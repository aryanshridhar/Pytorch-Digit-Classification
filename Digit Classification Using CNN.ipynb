{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root = '.' , download = True , transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: .\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "           0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "           0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "           0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "           0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "           0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "           0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "           0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "           0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "           0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "           0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "           0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "           0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "           0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "           0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "           0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOuUlEQVR4nO3df6xUdXrH8c+nqGnEH0iNSFgtizFYNZZtEBuXrBrD+iMavepultSERiP7hyRu0pAa+sdqWqypP5qlmg1s1IVmy7qJGtFuVo2obGtCvCIq4rK6xu6iN1CDKOAPCjz94w7mrt75zmXmzJzhPu9XMpmZ88yZeTLhwzlnvufcryNCAMa/P6m7AQC9QdiBJAg7kARhB5Ig7EAShB1IgrADSRB2jMr287Y/s727cdtSd0/oDGFHyaKIOKZxm1l3M+gMYQeSIOwo+WfbH9j+b9sX1t0MOmPOjcdobJ8nabOkvZK+J+k+SbMi4ne1Noa2EXaMie1fSfrPiPi3untBe9iNx1iFJNfdBNpH2PEVtifZvsT2n9o+wvbfSPqWpKfq7g3tO6LuBtCXjpT0T5LOkLRf0m8kXR0RjLUfxjhmB5JgNx5IgrADSRB2IAnCDiTR01/jbfNrINBlETHq+RAdbdltX2p7i+23bd/ayXsB6K62h95sT5D0W0nzJG2V9JKk+RGxubAOW3agy7qxZZ8j6e2IeCci9kr6uaSrOng/AF3USdinSfrDiOdbG8v+iO2FtgdtD3bwWQA61MkPdKPtKnxlNz0iVkhaIbEbD9Spky37VkmnjHj+NUnvd9YOgG7pJOwvSTrd9tdtH6XhP3Cwppq2AFSt7d34iNhne5GGL3ucIOnBiHijss4AVKqnV71xzA50X1dOqgFw+CDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgibanbMbhYcKECcX68ccf39XPX7RoUdPa0UcfXVx35syZxfrNN99crN99991Na/Pnzy+u+9lnnxXrd955Z7F+++23F+t16Cjstt+VtEvSfkn7ImJ2FU0BqF4VW/aLIuKDCt4HQBdxzA4k0WnYQ9LTtl+2vXC0F9heaHvQ9mCHnwWgA53uxn8zIt63fZKkZ2z/JiLWjXxBRKyQtEKSbEeHnwegTR1t2SPi/cb9dkmPSZpTRVMAqtd22G1PtH3swceSvi1pU1WNAahWJ7vxUyQ9Zvvg+/xHRPyqkq7GmVNPPbVYP+qoo4r1888/v1ifO3du09qkSZOK61577bXFep22bt1arC9btqxYHxgYaFrbtWtXcd1XX321WH/hhReK9X7Udtgj4h1Jf1lhLwC6iKE3IAnCDiRB2IEkCDuQBGEHknBE705qG69n0M2aNatYX7t2bbHe7ctM+9WBAweK9RtuuKFY3717d9ufPTQ0VKx/+OGHxfqWLVva/uxuiwiPtpwtO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7BSZPnlysr1+/vlifMWNGle1UqlXvO3fuLNYvuuiiprW9e/cW1816/kGnGGcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSSYsrkCO3bsKNYXL15crF9xxRXF+iuvvFKst/qTyiUbN24s1ufNm1es79mzp1g/66yzmtZuueWW4rqoFlt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC69n7wHHHHVest5peePny5U1rN954Y3Hd66+/vlhfvXp1sY7+0/b17LYftL3d9qYRyybbfsb2W437E6psFkD1xrIb/1NJl35p2a2Sno2I0yU923gOoI+1DHtErJP05fNBr5K0svF4paSrK+4LQMXaPTd+SkQMSVJEDNk+qdkLbS+UtLDNzwFQka5fCBMRKyStkPiBDqhTu0Nv22xPlaTG/fbqWgLQDe2GfY2kBY3HCyQ9Xk07ALql5W687dWSLpR0ou2tkn4o6U5Jv7B9o6TfS/pON5sc7z7++OOO1v/oo4/aXvemm24q1h9++OFivdUc6+gfLcMeEfOblC6uuBcAXcTpskAShB1IgrADSRB2IAnCDiTBJa7jwMSJE5vWnnjiieK6F1xwQbF+2WWXFetPP/10sY7eY8pmIDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfZx7rTTTivWN2zYUKzv3LmzWH/uueeK9cHBwaa1+++/v7huL/9tjieMswPJEXYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzJzcwMFCsP/TQQ8X6scce2/ZnL1mypFhftWpVsT40NNT2Z49njLMDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6Po7LPPLtbvvffeYv3ii9uf7Hf58uXF+tKlS4v19957r+3PPpy1Pc5u+0Hb221vGrHsNtvv2d7YuF1eZbMAqjeW3fifSrp0lOX/GhGzGrdfVtsWgKq1DHtErJO0owe9AOiiTn6gW2T7tcZu/gnNXmR7oe1B283/GBmArms37D+WdJqkWZKGJN3T7IURsSIiZkfE7DY/C0AF2gp7RGyLiP0RcUDSTyTNqbYtAFVrK+y2p454OiBpU7PXAugPLcfZba+WdKGkEyVtk/TDxvNZkkLSu5K+HxEtLy5mnH38mTRpUrF+5ZVXNq21ulbeHnW4+Atr164t1ufNm1esj1fNxtmPGMOK80dZ/EDHHQHoKU6XBZIg7EAShB1IgrADSRB2IAkucUVtPv/882L9iCPKg0X79u0r1i+55JKmteeff7647uGMPyUNJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0m0vOoNuZ1zzjnF+nXXXVesn3vuuU1rrcbRW9m8eXOxvm7duo7ef7xhyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOPs7NnDmzWF+0aFGxfs011xTrJ5988iH3NFb79+8v1oeGyn+9/MCBA1W2c9hjyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSbQcZ7d9iqRVkk6WdEDSioj4ke3Jkh6WNF3D0zZ/NyI+7F6rebUay54/f7SJdoe1GkefPn16Oy1VYnBwsFhfunRpsb5mzZoq2xn3xrJl3yfp7yLiLyT9taSbbZ8p6VZJz0bE6ZKebTwH0Kdahj0ihiJiQ+PxLklvSpom6SpJKxsvWynp6m41CaBzh3TMbnu6pG9IWi9pSkQMScP/IUg6qermAFRnzOfG2z5G0iOSfhARH9ujTic12noLJS1srz0AVRnTlt32kRoO+s8i4tHG4m22pzbqUyVtH23diFgREbMjYnYVDQNoT8uwe3gT/oCkNyPi3hGlNZIWNB4vkPR49e0BqErLKZttz5X0a0mva3joTZKWaPi4/ReSTpX0e0nfiYgdLd4r5ZTNU6ZMKdbPPPPMYv2+++4r1s8444xD7qkq69evL9bvuuuuprXHHy9vH7hEtT3NpmxuecweEf8lqdkB+sWdNAWgdziDDkiCsANJEHYgCcIOJEHYgSQIO5AEf0p6jCZPnty0tnz58uK6s2bNKtZnzJjRVk9VePHFF4v1e+65p1h/6qmnivVPP/30kHtCd7BlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk0oyzn3feecX64sWLi/U5c+Y0rU2bNq2tnqryySefNK0tW7asuO4dd9xRrO/Zs6etntB/2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJpxtkHBgY6qndi8+bNxfqTTz5ZrO/bt69YL11zvnPnzuK6yIMtO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kMZb52U+RtErSyRqen31FRPzI9m2SbpL0v42XLomIX7Z4r5TzswO91Gx+9rGEfaqkqRGxwfaxkl6WdLWk70raHRF3j7UJwg50X7OwtzyDLiKGJA01Hu+y/aakev80C4BDdkjH7LanS/qGpPWNRYtsv2b7QdsnNFlnoe1B24MddQqgIy134794oX2MpBckLY2IR21PkfSBpJD0jxre1b+hxXuwGw90WdvH7JJk+0hJT0p6KiLuHaU+XdKTEXF2i/ch7ECXNQt7y91425b0gKQ3Rwa98cPdQQOSNnXaJIDuGcuv8XMl/VrS6xoeepOkJZLmS5ql4d34dyV9v/FjXum92LIDXdbRbnxVCDvQfW3vxgMYHwg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9HrK5g8k/c+I5yc2lvWjfu2tX/uS6K1dVfb2580KPb2e/Ssfbg9GxOzaGijo1976tS+J3trVq97YjQeSIOxAEnWHfUXNn1/Sr731a18SvbWrJ73VeswOoHfq3rID6BHCDiRRS9htX2p7i+23bd9aRw/N2H7X9uu2N9Y9P11jDr3ttjeNWDbZ9jO232rcjzrHXk293Wb7vcZ3t9H25TX1dort52y/afsN27c0ltf63RX66sn31vNjdtsTJP1W0jxJWyW9JGl+RGzuaSNN2H5X0uyIqP0EDNvfkrRb0qqDU2vZ/hdJOyLizsZ/lCdExN/3SW+36RCn8e5Sb82mGf9b1fjdVTn9eTvq2LLPkfR2RLwTEXsl/VzSVTX00fciYp2kHV9afJWklY3HKzX8j6XnmvTWFyJiKCI2NB7vknRwmvFav7tCXz1RR9inSfrDiOdb1V/zvYekp22/bHth3c2MYsrBabYa9yfV3M+XtZzGu5e+NM1433x37Ux/3qk6wj7a1DT9NP73zYj4K0mXSbq5sbuKsfmxpNM0PAfgkKR76mymMc34I5J+EBEf19nLSKP01ZPvrY6wb5V0yojnX5P0fg19jCoi3m/cb5f0mIYPO/rJtoMz6Dbut9fczxciYltE7I+IA5J+ohq/u8Y0449I+llEPNpYXPt3N1pfvfre6gj7S5JOt/1120dJ+p6kNTX08RW2JzZ+OJHtiZK+rf6binqNpAWNxwskPV5jL3+kX6bxbjbNuGr+7mqf/jwien6TdLmGf5H/naR/qKOHJn3NkPRq4/ZG3b1JWq3h3br/0/Ae0Y2S/kzSs5LeatxP7qPe/l3DU3u/puFgTa2pt7kaPjR8TdLGxu3yur+7Ql89+d44XRZIgjPogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wdTTaw/QgR51gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[0][0][0,:,:] , cmap = 'gray')\n",
    "plt.title(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '9')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[110][0][0,:,:] , cmap = 'gray')\n",
    "plt.title(dataset[110][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_dl = DataLoader(dataset , batch_size , sampler = SubsetRandomSampler(np.random.permutation(len(dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "tensor([3, 5, 0, 1, 6, 0, 6, 4, 6, 5, 4, 0, 7, 7, 7, 1, 4, 9, 0, 7, 1, 7, 1, 6,\n",
      "        1, 0, 8, 6, 4, 6, 0, 8, 2, 2, 7, 3, 5, 2, 4, 0, 0, 5, 3, 1, 1, 2, 2, 1,\n",
      "        4, 1, 6, 1, 8, 5, 9, 1, 1, 0, 6, 1, 5, 4, 7, 7, 2, 9, 0, 4, 9, 3, 5, 6,\n",
      "        3, 4, 8, 2, 3, 3, 6, 2, 9, 1, 7, 2, 2, 2, 9, 9, 0, 4, 3, 3, 3, 2, 0, 0,\n",
      "        4, 1, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_dl:\n",
    "    print(image.shape)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,8,3,1,2) \n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(8,16,3,1,1)\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16,32,3,1,2)\n",
    "        self.pool3 = nn.MaxPool2d(2,2) \n",
    "        \n",
    "        self.conv4 = nn.Conv2d(32,64,3,1,1)\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        \n",
    "        self.linear1 = nn.Linear(256 , 32)\n",
    "        self.linear2 = nn.Linear(32,10)\n",
    "    \n",
    "    def forward(self , batch):\n",
    "        out = self.pool1(F.relu(self.conv1(batch)))\n",
    "        out = self.pool2(F.relu(self.conv2(out)))\n",
    "        out = self.pool3(F.relu(self.conv3(out)))\n",
    "        out = self.pool4(F.relu(self.conv4(out)))\n",
    "        \n",
    "        out = self.flat(out)\n",
    "        \n",
    "        out = self.linear1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DigitClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[ 2.4067e-01, -1.7103e-02, -5.2850e-02],\n",
       "           [-6.3094e-02,  4.7007e-02,  2.2296e-01],\n",
       "           [-2.4726e-01,  8.7985e-02,  2.3886e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2350e-04, -1.0447e-01, -1.1183e-01],\n",
       "           [-1.1370e-01,  1.4180e-01,  1.1177e-01],\n",
       "           [ 3.3063e-01, -1.7588e-01, -2.8195e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5846e-01, -1.8236e-01, -1.0803e-01],\n",
       "           [-1.9248e-02,  2.6913e-01, -1.8813e-01],\n",
       "           [ 3.3247e-01, -2.6526e-02,  8.5319e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.7901e-01, -4.8437e-02, -1.7249e-02],\n",
       "           [ 2.7332e-01,  1.0875e-01,  1.9451e-03],\n",
       "           [ 3.4482e-02,  9.9327e-02,  1.3507e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.2544e-01,  1.1096e-01,  3.1899e-01],\n",
       "           [ 3.2592e-01, -3.1069e-01,  1.9772e-01],\n",
       "           [ 1.3540e-01,  2.9605e-01,  9.5258e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.7430e-02, -1.1395e-02,  1.9853e-01],\n",
       "           [ 3.1622e-01, -5.3895e-02,  2.3553e-01],\n",
       "           [-1.1795e-01,  2.6592e-01, -1.8392e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.2592e-02, -3.1965e-01,  1.5327e-01],\n",
       "           [-2.4820e-01,  1.4968e-01,  2.0063e-01],\n",
       "           [ 3.2989e-01,  1.8526e-01,  7.6273e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.1636e-01, -2.4245e-01,  1.7774e-01],\n",
       "           [-7.7731e-02,  2.0014e-01, -9.6387e-02],\n",
       "           [-3.2073e-01,  2.1382e-01,  2.9488e-01]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1391, -0.1887,  0.2991,  0.0828, -0.1696,  0.2354, -0.1245, -0.1753],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0988,  0.0722, -0.1072],\n",
       "           [-0.0465, -0.0379, -0.0286],\n",
       "           [-0.0606, -0.1115, -0.0441]],\n",
       " \n",
       "          [[ 0.0590, -0.0126,  0.0657],\n",
       "           [-0.0230,  0.0768,  0.1037],\n",
       "           [ 0.0494, -0.0695,  0.1051]],\n",
       " \n",
       "          [[-0.0081,  0.0535,  0.0251],\n",
       "           [ 0.0368, -0.0583,  0.0943],\n",
       "           [ 0.0273, -0.0887,  0.1124]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1079, -0.0139,  0.0857],\n",
       "           [ 0.0386,  0.0045, -0.0241],\n",
       "           [-0.0603, -0.1125,  0.0927]],\n",
       " \n",
       "          [[ 0.0268, -0.0009,  0.0204],\n",
       "           [-0.0416,  0.0145,  0.0615],\n",
       "           [-0.0969,  0.0308, -0.1032]],\n",
       " \n",
       "          [[ 0.0227,  0.1040,  0.0677],\n",
       "           [ 0.1168,  0.0313, -0.0197],\n",
       "           [ 0.0561,  0.0610, -0.0257]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0169, -0.0445, -0.0971],\n",
       "           [-0.0227,  0.0975,  0.0304],\n",
       "           [ 0.0849, -0.0072,  0.0334]],\n",
       " \n",
       "          [[-0.0448,  0.0766, -0.0143],\n",
       "           [-0.0071, -0.0483,  0.0483],\n",
       "           [ 0.0523, -0.0508,  0.1067]],\n",
       " \n",
       "          [[-0.0711, -0.0181,  0.0296],\n",
       "           [-0.0923,  0.0066, -0.0329],\n",
       "           [-0.0393, -0.1146,  0.0654]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0707, -0.0510,  0.0718],\n",
       "           [ 0.1022,  0.1080,  0.1156],\n",
       "           [-0.1166, -0.1175, -0.0803]],\n",
       " \n",
       "          [[ 0.0401, -0.0425,  0.0691],\n",
       "           [-0.0264, -0.0140, -0.0709],\n",
       "           [-0.0797,  0.0470,  0.1030]],\n",
       " \n",
       "          [[-0.0650, -0.0731, -0.0363],\n",
       "           [ 0.0293,  0.1107,  0.0555],\n",
       "           [ 0.0636, -0.0246,  0.1028]]],\n",
       " \n",
       " \n",
       "         [[[-0.0918,  0.0291,  0.0998],\n",
       "           [ 0.0814,  0.1101, -0.0453],\n",
       "           [-0.0232,  0.0206, -0.0931]],\n",
       " \n",
       "          [[ 0.0081,  0.1138, -0.0261],\n",
       "           [ 0.0277, -0.0858, -0.0552],\n",
       "           [-0.0368,  0.0689,  0.0443]],\n",
       " \n",
       "          [[-0.0940, -0.0681,  0.0971],\n",
       "           [ 0.1126,  0.0941, -0.1064],\n",
       "           [ 0.0873,  0.0901,  0.0675]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0559, -0.0611, -0.0259],\n",
       "           [ 0.0017, -0.0585, -0.0726],\n",
       "           [-0.0062, -0.0895,  0.0992]],\n",
       " \n",
       "          [[-0.0421, -0.1074,  0.0870],\n",
       "           [-0.0133, -0.0193, -0.0223],\n",
       "           [ 0.0125, -0.0826,  0.0987]],\n",
       " \n",
       "          [[-0.0497, -0.0340, -0.0727],\n",
       "           [-0.0235, -0.0765, -0.0066],\n",
       "           [ 0.0561, -0.1128, -0.0537]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0433, -0.0745,  0.0256],\n",
       "           [-0.0501,  0.0889,  0.0489],\n",
       "           [ 0.0463,  0.0351, -0.0477]],\n",
       " \n",
       "          [[ 0.0502,  0.0011,  0.0721],\n",
       "           [ 0.0906, -0.0329, -0.0313],\n",
       "           [ 0.0099,  0.0139,  0.0646]],\n",
       " \n",
       "          [[ 0.0681,  0.0332, -0.0556],\n",
       "           [ 0.1035,  0.0809,  0.1000],\n",
       "           [-0.0393,  0.0473, -0.1008]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0620,  0.0754, -0.0713],\n",
       "           [-0.0368,  0.0494, -0.0432],\n",
       "           [-0.0468,  0.0137, -0.1011]],\n",
       " \n",
       "          [[ 0.0631,  0.0413,  0.1048],\n",
       "           [-0.0375, -0.1162,  0.0906],\n",
       "           [ 0.0173, -0.0861, -0.0541]],\n",
       " \n",
       "          [[ 0.0896, -0.0180,  0.0797],\n",
       "           [-0.0539, -0.0749,  0.1140],\n",
       "           [ 0.0862, -0.0665, -0.0680]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0187, -0.0745,  0.0214],\n",
       "           [ 0.0755, -0.0776,  0.0146],\n",
       "           [ 0.0529, -0.0874,  0.0289]],\n",
       " \n",
       "          [[ 0.0041, -0.0968,  0.0530],\n",
       "           [ 0.1141,  0.0827,  0.1024],\n",
       "           [ 0.0583,  0.0036, -0.0427]],\n",
       " \n",
       "          [[ 0.1042,  0.0473,  0.0356],\n",
       "           [ 0.0619, -0.0708, -0.0808],\n",
       "           [ 0.0393,  0.0730, -0.0322]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0138,  0.1128,  0.0418],\n",
       "           [-0.0572,  0.0026,  0.0856],\n",
       "           [ 0.0993, -0.0402,  0.0205]],\n",
       " \n",
       "          [[ 0.0380, -0.0091,  0.0165],\n",
       "           [-0.0735,  0.0680, -0.0423],\n",
       "           [-0.0514,  0.0642, -0.0735]],\n",
       " \n",
       "          [[ 0.0049, -0.0079, -0.0652],\n",
       "           [ 0.0617, -0.0637,  0.0060],\n",
       "           [ 0.0954, -0.0202, -0.0561]]],\n",
       " \n",
       " \n",
       "         [[[-0.0328, -0.0242,  0.1045],\n",
       "           [-0.0449,  0.0568,  0.0905],\n",
       "           [ 0.1109, -0.0231, -0.0387]],\n",
       " \n",
       "          [[-0.0459, -0.0353,  0.0159],\n",
       "           [ 0.0370, -0.0189,  0.0430],\n",
       "           [ 0.0797,  0.0286,  0.0994]],\n",
       " \n",
       "          [[ 0.0629, -0.0571,  0.1138],\n",
       "           [-0.0696, -0.0118, -0.1021],\n",
       "           [ 0.0486,  0.1072, -0.0934]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0724, -0.0215, -0.0280],\n",
       "           [ 0.0291,  0.0895,  0.0828],\n",
       "           [ 0.0063,  0.0128, -0.0358]],\n",
       " \n",
       "          [[ 0.0249, -0.0587, -0.0166],\n",
       "           [ 0.0042, -0.0837,  0.1074],\n",
       "           [ 0.1010,  0.0473, -0.0290]],\n",
       " \n",
       "          [[ 0.0501, -0.0944,  0.0097],\n",
       "           [ 0.1091, -0.0571, -0.0250],\n",
       "           [-0.1116,  0.1022, -0.1050]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1132, -0.0775,  0.0845,  0.0091,  0.0737,  0.0864,  0.0674,  0.0503,\n",
       "          0.1131, -0.0358,  0.1146,  0.0186, -0.0706, -0.0080,  0.0695, -0.1059],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 3.0532e-03,  2.5580e-02,  4.9757e-02],\n",
       "           [-2.3919e-02,  7.0578e-02,  2.2771e-02],\n",
       "           [-3.5018e-05,  1.7535e-02, -8.0750e-02]],\n",
       " \n",
       "          [[-3.9230e-02, -7.3491e-03, -1.4804e-02],\n",
       "           [-1.9591e-02,  6.1921e-02, -4.4443e-02],\n",
       "           [-6.8311e-02,  1.1235e-02,  2.6317e-02]],\n",
       " \n",
       "          [[-8.1049e-02, -3.9125e-02,  7.5068e-02],\n",
       "           [-8.1931e-02,  7.6446e-02, -5.9533e-02],\n",
       "           [ 1.7271e-02,  3.2310e-02,  6.7294e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.6447e-02,  5.0686e-02, -7.1835e-02],\n",
       "           [ 6.3970e-03, -2.9700e-02,  2.4838e-02],\n",
       "           [ 6.0345e-02,  5.4012e-02, -3.6786e-03]],\n",
       " \n",
       "          [[ 2.2067e-02,  4.5702e-02,  3.1853e-02],\n",
       "           [ 6.0299e-02,  7.1389e-02, -6.0185e-02],\n",
       "           [-3.5681e-02, -7.2047e-02,  6.5073e-02]],\n",
       " \n",
       "          [[ 6.0861e-02,  3.9792e-02,  3.2068e-02],\n",
       "           [-6.1556e-02,  3.3627e-02, -7.0580e-02],\n",
       "           [-1.9279e-02, -6.7703e-02, -5.5220e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.9473e-02, -3.1530e-02, -4.1208e-02],\n",
       "           [-3.3239e-02,  2.5700e-02,  7.0013e-02],\n",
       "           [ 1.6395e-02, -3.7984e-02,  2.1659e-02]],\n",
       " \n",
       "          [[ 4.1375e-02, -4.1087e-02,  5.9631e-02],\n",
       "           [-3.2317e-03, -5.9741e-03,  1.9974e-02],\n",
       "           [ 4.2261e-02, -2.2270e-02, -7.0951e-02]],\n",
       " \n",
       "          [[ 2.2451e-02, -5.2160e-02, -6.1418e-02],\n",
       "           [ 5.4409e-02, -5.7840e-02,  3.0290e-02],\n",
       "           [-1.2747e-02, -3.6182e-02,  2.4341e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.5755e-02,  1.0793e-02,  7.1401e-02],\n",
       "           [ 7.0167e-02, -2.8171e-02, -1.9626e-02],\n",
       "           [-2.1025e-02,  4.4303e-02,  2.4424e-02]],\n",
       " \n",
       "          [[ 5.6543e-02,  6.7593e-02,  4.8597e-03],\n",
       "           [ 5.9497e-02, -7.7326e-02,  2.1927e-02],\n",
       "           [-1.9716e-02, -1.1645e-02, -4.0201e-02]],\n",
       " \n",
       "          [[-2.0903e-04, -3.0970e-02, -7.2508e-02],\n",
       "           [ 7.2283e-02,  2.6996e-02, -6.3164e-02],\n",
       "           [ 1.2091e-02, -7.5581e-02,  7.7371e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.9364e-03, -2.1546e-02, -7.1805e-02],\n",
       "           [ 1.7676e-02, -7.6656e-02,  2.5618e-02],\n",
       "           [-3.7756e-02,  3.9500e-02,  3.8149e-02]],\n",
       " \n",
       "          [[ 3.1943e-02, -4.9882e-02, -7.1349e-02],\n",
       "           [-1.3233e-03, -8.2215e-02, -3.8686e-02],\n",
       "           [-7.7398e-02,  7.4724e-02,  3.4470e-02]],\n",
       " \n",
       "          [[-6.8765e-02, -1.7285e-02, -5.7735e-02],\n",
       "           [-7.8681e-02, -6.9476e-02, -1.0496e-02],\n",
       "           [-2.5923e-02,  2.6200e-02,  6.3346e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.2009e-02, -6.2637e-02,  5.6820e-02],\n",
       "           [ 6.2082e-02,  3.0752e-02, -4.4692e-02],\n",
       "           [-9.5353e-03,  1.6073e-03, -8.2912e-02]],\n",
       " \n",
       "          [[-7.2994e-02,  4.0931e-02, -6.4848e-02],\n",
       "           [ 1.4597e-02, -7.3123e-02, -7.9037e-02],\n",
       "           [-1.8317e-02,  1.4310e-02,  6.4568e-03]],\n",
       " \n",
       "          [[-1.0125e-02, -7.4392e-02, -1.1453e-02],\n",
       "           [-7.9775e-02, -5.5088e-02,  3.5922e-02],\n",
       "           [ 6.2461e-02, -6.6429e-02, -4.6142e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-2.3406e-02, -5.9255e-02,  7.8262e-02],\n",
       "           [-7.3705e-02, -3.8604e-02,  2.0753e-02],\n",
       "           [-7.1413e-04, -1.4548e-02,  5.9302e-02]],\n",
       " \n",
       "          [[-6.7258e-02,  3.3459e-03, -4.9253e-02],\n",
       "           [ 9.5177e-03,  5.9351e-02,  2.1036e-02],\n",
       "           [ 3.2331e-02, -6.1873e-02,  7.8824e-02]],\n",
       " \n",
       "          [[ 8.5034e-03, -1.0512e-02, -2.3555e-02],\n",
       "           [ 2.5311e-02,  1.1660e-02, -8.1148e-04],\n",
       "           [-4.1912e-02, -8.2587e-02, -1.3456e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.1117e-02,  4.5134e-02, -5.7004e-02],\n",
       "           [ 7.2388e-02, -6.5307e-02,  3.9928e-02],\n",
       "           [ 4.9370e-03, -5.2538e-02,  5.9375e-03]],\n",
       " \n",
       "          [[ 4.8543e-02,  3.8590e-02,  5.7315e-02],\n",
       "           [ 2.3692e-02,  2.8069e-02,  8.0825e-02],\n",
       "           [-2.4731e-02,  6.3478e-02, -3.8326e-02]],\n",
       " \n",
       "          [[ 1.0116e-02, -4.7581e-02,  7.5882e-02],\n",
       "           [-8.0811e-02,  2.7775e-02, -6.4014e-02],\n",
       "           [ 4.0525e-02,  5.7200e-02,  2.1391e-02]]],\n",
       " \n",
       " \n",
       "         [[[-7.4678e-02, -4.8527e-02, -2.0958e-02],\n",
       "           [-3.9324e-02,  5.2205e-03, -5.4497e-02],\n",
       "           [ 2.5196e-02, -2.1151e-02,  3.8062e-02]],\n",
       " \n",
       "          [[-2.3517e-02, -8.0775e-02,  8.0859e-02],\n",
       "           [-1.9835e-02,  6.4328e-02, -3.8576e-02],\n",
       "           [ 5.4484e-02, -4.2322e-02,  7.2073e-03]],\n",
       " \n",
       "          [[-5.5289e-02,  2.7351e-02, -5.6353e-02],\n",
       "           [ 8.1970e-02, -6.0289e-02, -6.6874e-02],\n",
       "           [ 2.8754e-02, -2.1132e-02, -3.2470e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.3195e-02,  3.9092e-02,  1.0517e-02],\n",
       "           [ 2.0737e-02, -5.7729e-02, -5.4973e-02],\n",
       "           [ 1.4740e-02, -4.5467e-03, -6.8271e-02]],\n",
       " \n",
       "          [[ 5.2901e-02,  4.6397e-02, -5.5808e-02],\n",
       "           [ 7.4873e-02, -6.7109e-02,  5.7887e-02],\n",
       "           [-2.4440e-02,  3.2056e-02,  6.0359e-02]],\n",
       " \n",
       "          [[-7.2139e-02, -4.0759e-02,  7.5138e-02],\n",
       "           [-3.8507e-02,  3.3414e-03,  2.1111e-03],\n",
       "           [-1.5768e-02, -3.5015e-02,  6.5439e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.2370e-02, -4.3779e-02, -2.7448e-02],\n",
       "           [ 2.4691e-02,  6.2530e-02,  4.5076e-04],\n",
       "           [-3.6769e-02,  1.4993e-02, -4.9714e-02]],\n",
       " \n",
       "          [[-6.3365e-02,  5.6557e-02,  4.2600e-02],\n",
       "           [-5.3746e-02,  1.9307e-02, -3.1423e-02],\n",
       "           [-4.4925e-02, -6.1807e-03,  2.4828e-02]],\n",
       " \n",
       "          [[-3.4462e-02, -2.6169e-02,  2.2672e-03],\n",
       "           [-4.0825e-02,  5.5152e-02,  2.4428e-02],\n",
       "           [ 7.3039e-02,  2.0673e-02,  6.1862e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.5277e-02,  5.8915e-02, -6.8714e-02],\n",
       "           [-7.3260e-02, -7.7609e-02, -4.4352e-02],\n",
       "           [ 8.0868e-02,  6.5010e-02,  2.2865e-02]],\n",
       " \n",
       "          [[-5.8459e-02, -4.8008e-02, -6.0334e-02],\n",
       "           [ 1.4597e-02, -2.9096e-02,  3.8272e-02],\n",
       "           [-5.6630e-02,  6.3591e-02, -3.3187e-03]],\n",
       " \n",
       "          [[ 4.4330e-02,  6.4722e-02,  7.9731e-02],\n",
       "           [-6.3940e-02, -5.5008e-02, -1.3947e-02],\n",
       "           [-5.2315e-02, -4.6540e-02, -2.2170e-02]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0791, -0.0576,  0.0555,  0.0617, -0.0063, -0.0225,  0.0298,  0.0411,\n",
       "         -0.0802, -0.0808,  0.0545,  0.0325, -0.0232,  0.0109,  0.0285, -0.0584,\n",
       "         -0.0688,  0.0469,  0.0443,  0.0539, -0.0259,  0.0266,  0.0759, -0.0234,\n",
       "         -0.0142,  0.0770,  0.0337, -0.0827,  0.0502, -0.0114, -0.0705,  0.0641],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0335, -0.0345,  0.0118],\n",
       "           [-0.0097, -0.0302, -0.0584],\n",
       "           [-0.0156, -0.0107, -0.0391]],\n",
       " \n",
       "          [[-0.0391,  0.0448,  0.0504],\n",
       "           [-0.0253,  0.0236,  0.0318],\n",
       "           [-0.0397,  0.0481,  0.0555]],\n",
       " \n",
       "          [[-0.0541, -0.0053, -0.0434],\n",
       "           [-0.0034,  0.0069, -0.0458],\n",
       "           [ 0.0211, -0.0334, -0.0546]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0539,  0.0529,  0.0304],\n",
       "           [-0.0256, -0.0518,  0.0165],\n",
       "           [-0.0110, -0.0175,  0.0071]],\n",
       " \n",
       "          [[ 0.0320,  0.0335,  0.0257],\n",
       "           [ 0.0299,  0.0443, -0.0276],\n",
       "           [ 0.0332, -0.0395, -0.0446]],\n",
       " \n",
       "          [[ 0.0095,  0.0526,  0.0100],\n",
       "           [-0.0068, -0.0018, -0.0314],\n",
       "           [ 0.0393,  0.0531,  0.0296]]],\n",
       " \n",
       " \n",
       "         [[[-0.0413,  0.0587,  0.0294],\n",
       "           [ 0.0395,  0.0586,  0.0454],\n",
       "           [ 0.0200,  0.0494, -0.0081]],\n",
       " \n",
       "          [[ 0.0417,  0.0134,  0.0162],\n",
       "           [-0.0474,  0.0488, -0.0516],\n",
       "           [ 0.0184,  0.0019, -0.0587]],\n",
       " \n",
       "          [[-0.0075, -0.0211, -0.0467],\n",
       "           [-0.0020,  0.0226, -0.0329],\n",
       "           [ 0.0564, -0.0102,  0.0060]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0293,  0.0180,  0.0362],\n",
       "           [ 0.0505,  0.0202,  0.0549],\n",
       "           [ 0.0413, -0.0443,  0.0256]],\n",
       " \n",
       "          [[-0.0566, -0.0386, -0.0578],\n",
       "           [-0.0139, -0.0244, -0.0010],\n",
       "           [ 0.0177, -0.0257,  0.0260]],\n",
       " \n",
       "          [[ 0.0423,  0.0295, -0.0386],\n",
       "           [-0.0509,  0.0333,  0.0018],\n",
       "           [-0.0567,  0.0052, -0.0294]]],\n",
       " \n",
       " \n",
       "         [[[-0.0202, -0.0555,  0.0461],\n",
       "           [-0.0578,  0.0234,  0.0111],\n",
       "           [-0.0431, -0.0425, -0.0237]],\n",
       " \n",
       "          [[ 0.0376, -0.0151,  0.0219],\n",
       "           [ 0.0041, -0.0080, -0.0026],\n",
       "           [ 0.0152,  0.0190,  0.0382]],\n",
       " \n",
       "          [[ 0.0345, -0.0153, -0.0574],\n",
       "           [ 0.0566, -0.0430, -0.0259],\n",
       "           [-0.0384, -0.0407, -0.0170]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0433, -0.0277,  0.0530],\n",
       "           [ 0.0075, -0.0489,  0.0221],\n",
       "           [-0.0304, -0.0434, -0.0392]],\n",
       " \n",
       "          [[ 0.0076,  0.0557,  0.0543],\n",
       "           [ 0.0453, -0.0228,  0.0546],\n",
       "           [-0.0423, -0.0246,  0.0130]],\n",
       " \n",
       "          [[ 0.0444,  0.0255,  0.0104],\n",
       "           [-0.0099, -0.0403,  0.0342],\n",
       "           [-0.0341,  0.0579, -0.0311]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0472, -0.0474,  0.0169],\n",
       "           [ 0.0576, -0.0453, -0.0516],\n",
       "           [ 0.0058,  0.0461, -0.0587]],\n",
       " \n",
       "          [[ 0.0167, -0.0555, -0.0422],\n",
       "           [ 0.0015, -0.0119,  0.0580],\n",
       "           [ 0.0568, -0.0468, -0.0443]],\n",
       " \n",
       "          [[ 0.0294,  0.0546,  0.0489],\n",
       "           [ 0.0242, -0.0105,  0.0329],\n",
       "           [-0.0213,  0.0055, -0.0028]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0385,  0.0525,  0.0399],\n",
       "           [ 0.0301,  0.0560, -0.0209],\n",
       "           [ 0.0069, -0.0446, -0.0353]],\n",
       " \n",
       "          [[-0.0507,  0.0012,  0.0248],\n",
       "           [-0.0131, -0.0556, -0.0253],\n",
       "           [ 0.0357, -0.0105,  0.0556]],\n",
       " \n",
       "          [[ 0.0249,  0.0321, -0.0459],\n",
       "           [ 0.0051,  0.0458, -0.0439],\n",
       "           [ 0.0466, -0.0537, -0.0257]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0155, -0.0407, -0.0278],\n",
       "           [ 0.0352, -0.0097,  0.0431],\n",
       "           [-0.0010, -0.0170,  0.0355]],\n",
       " \n",
       "          [[-0.0440, -0.0234,  0.0030],\n",
       "           [-0.0011, -0.0360, -0.0389],\n",
       "           [ 0.0226,  0.0282, -0.0035]],\n",
       " \n",
       "          [[-0.0490, -0.0364,  0.0151],\n",
       "           [ 0.0202, -0.0069,  0.0253],\n",
       "           [-0.0432,  0.0312, -0.0393]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0124, -0.0157, -0.0472],\n",
       "           [-0.0021,  0.0318,  0.0072],\n",
       "           [-0.0124,  0.0363, -0.0464]],\n",
       " \n",
       "          [[ 0.0250,  0.0236,  0.0336],\n",
       "           [-0.0162, -0.0315, -0.0543],\n",
       "           [ 0.0513, -0.0428, -0.0143]],\n",
       " \n",
       "          [[-0.0104, -0.0098,  0.0349],\n",
       "           [ 0.0152,  0.0192, -0.0363],\n",
       "           [ 0.0176, -0.0448,  0.0154]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0127, -0.0448,  0.0286],\n",
       "           [ 0.0302, -0.0031, -0.0161],\n",
       "           [ 0.0167, -0.0580, -0.0342]],\n",
       " \n",
       "          [[-0.0515, -0.0484, -0.0261],\n",
       "           [ 0.0216, -0.0133,  0.0151],\n",
       "           [ 0.0021,  0.0571,  0.0140]],\n",
       " \n",
       "          [[ 0.0310, -0.0285, -0.0448],\n",
       "           [-0.0316,  0.0054,  0.0329],\n",
       "           [-0.0026,  0.0567, -0.0374]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0271,  0.0285, -0.0443],\n",
       "           [-0.0160, -0.0418,  0.0343],\n",
       "           [ 0.0525, -0.0538,  0.0122]],\n",
       " \n",
       "          [[-0.0511, -0.0335, -0.0235],\n",
       "           [ 0.0577, -0.0136, -0.0390],\n",
       "           [-0.0094, -0.0352, -0.0505]],\n",
       " \n",
       "          [[ 0.0396,  0.0312, -0.0200],\n",
       "           [-0.0248, -0.0414, -0.0176],\n",
       "           [ 0.0527, -0.0407, -0.0571]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0203,  0.0076, -0.0352,  0.0276,  0.0555,  0.0384, -0.0289,  0.0202,\n",
       "          0.0468,  0.0181,  0.0359, -0.0029,  0.0094, -0.0478, -0.0542, -0.0420,\n",
       "          0.0327, -0.0128, -0.0528, -0.0561, -0.0181, -0.0306, -0.0411,  0.0321,\n",
       "          0.0501, -0.0303,  0.0014,  0.0218,  0.0282,  0.0114, -0.0384, -0.0342,\n",
       "          0.0520,  0.0397, -0.0019, -0.0470, -0.0042,  0.0349,  0.0090,  0.0549,\n",
       "          0.0465, -0.0150, -0.0321,  0.0426,  0.0526, -0.0341, -0.0157,  0.0412,\n",
       "         -0.0407,  0.0076, -0.0460,  0.0067,  0.0542, -0.0237, -0.0101,  0.0479,\n",
       "         -0.0246,  0.0530, -0.0210, -0.0288,  0.0516, -0.0576, -0.0117,  0.0331],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0537, -0.0510, -0.0183,  ..., -0.0625, -0.0303, -0.0161],\n",
       "         [-0.0372, -0.0349, -0.0465,  ...,  0.0082, -0.0333,  0.0146],\n",
       "         [-0.0236, -0.0098,  0.0039,  ..., -0.0278,  0.0136, -0.0415],\n",
       "         ...,\n",
       "         [ 0.0083,  0.0590,  0.0549,  ..., -0.0225, -0.0218,  0.0284],\n",
       "         [-0.0425,  0.0185, -0.0416,  ...,  0.0292,  0.0097,  0.0092],\n",
       "         [ 0.0558, -0.0134, -0.0476,  ..., -0.0400, -0.0550,  0.0524]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0345, -0.0531,  0.0457, -0.0297,  0.0103, -0.0462,  0.0125,  0.0583,\n",
       "         -0.0384, -0.0151,  0.0041, -0.0047,  0.0510, -0.0244, -0.0366, -0.0049,\n",
       "          0.0160,  0.0200,  0.0458, -0.0275,  0.0198, -0.0430,  0.0538, -0.0326,\n",
       "          0.0474, -0.0466,  0.0496, -0.0109, -0.0545,  0.0164, -0.0453,  0.0609],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0137, -0.0181, -0.1734,  0.1082, -0.0070,  0.1300, -0.1732, -0.1671,\n",
       "          -0.0677,  0.0885,  0.1133,  0.1546, -0.0681,  0.0066, -0.0063, -0.0116,\n",
       "           0.0702,  0.0832,  0.0517,  0.1126, -0.1691,  0.1104, -0.1339, -0.0793,\n",
       "           0.1141,  0.1636,  0.1186, -0.1767,  0.1530, -0.1502, -0.0580, -0.1592],\n",
       "         [ 0.0376, -0.0822,  0.1491, -0.1094, -0.1413, -0.0697, -0.0904,  0.0104,\n",
       "          -0.1422, -0.1230, -0.0012,  0.0406,  0.0423,  0.1470,  0.1592,  0.1491,\n",
       "          -0.0708, -0.0506, -0.0347,  0.1618, -0.1212,  0.1636,  0.1743, -0.0813,\n",
       "           0.0993, -0.1521, -0.0628, -0.0345,  0.0157, -0.1507, -0.1625, -0.1692],\n",
       "         [-0.1529,  0.1628, -0.0847,  0.1182,  0.0784,  0.0742, -0.1456,  0.1724,\n",
       "          -0.1266,  0.1734,  0.1235,  0.0221,  0.0952,  0.1336,  0.1194, -0.0270,\n",
       "          -0.1208, -0.1426,  0.1006, -0.1390, -0.1594, -0.0238, -0.0287,  0.1544,\n",
       "           0.1307, -0.1326, -0.0754, -0.0867, -0.0402,  0.0649, -0.1665,  0.0493],\n",
       "         [ 0.1466,  0.0867, -0.1122,  0.1258,  0.1075,  0.0886, -0.1568, -0.1755,\n",
       "          -0.0469,  0.1232, -0.1692, -0.0181,  0.0370, -0.0630, -0.0907,  0.1364,\n",
       "           0.0512,  0.1444, -0.1192,  0.1182,  0.0772,  0.0595, -0.0684, -0.1328,\n",
       "           0.1144,  0.0307, -0.0490,  0.0986,  0.1258,  0.1348,  0.1026, -0.0194],\n",
       "         [-0.0975, -0.0250, -0.1154,  0.0673,  0.0035,  0.0484,  0.1420, -0.0722,\n",
       "          -0.0218, -0.0561, -0.1480, -0.1679,  0.1098, -0.1448,  0.0027,  0.1005,\n",
       "          -0.1083, -0.1093,  0.0132, -0.1662, -0.0999, -0.1620,  0.1233,  0.0040,\n",
       "           0.1629,  0.0603, -0.0757,  0.0160,  0.0982,  0.1251, -0.0286, -0.1285],\n",
       "         [-0.0533, -0.0227,  0.0918, -0.1630, -0.1466,  0.0365, -0.0429, -0.1089,\n",
       "          -0.0754,  0.1276, -0.0385, -0.1083, -0.0167,  0.0732,  0.0442, -0.0787,\n",
       "           0.1349, -0.1301,  0.0979,  0.1379,  0.1503,  0.1198, -0.1163,  0.0378,\n",
       "          -0.1204, -0.1097, -0.0975, -0.0366, -0.1054, -0.0140,  0.0806, -0.1100],\n",
       "         [-0.1755,  0.1489, -0.0878,  0.0729, -0.1747,  0.0620,  0.0641,  0.0634,\n",
       "           0.0339, -0.0704,  0.1134, -0.0987,  0.1316,  0.1038,  0.0250,  0.0500,\n",
       "          -0.0040, -0.1002,  0.0034,  0.0031,  0.0651,  0.0276,  0.0799, -0.0120,\n",
       "          -0.0578, -0.0304, -0.1509,  0.1605, -0.0777, -0.0014,  0.1553,  0.1435],\n",
       "         [-0.0279, -0.0548, -0.1412, -0.1031,  0.0362, -0.1651,  0.1046,  0.0078,\n",
       "          -0.1518, -0.0274,  0.1546, -0.0048,  0.1161, -0.0924, -0.0565,  0.1444,\n",
       "           0.1182,  0.0890,  0.0692, -0.1107, -0.1730, -0.1064, -0.0169,  0.1099,\n",
       "           0.0570, -0.1761, -0.1242, -0.0797,  0.1586, -0.0808,  0.0364,  0.0371],\n",
       "         [-0.1650,  0.0907, -0.0608, -0.0083, -0.0717, -0.0638,  0.0591, -0.0162,\n",
       "          -0.1623, -0.0539,  0.1218, -0.1402, -0.0384,  0.0533, -0.1448,  0.1060,\n",
       "           0.1751, -0.0216,  0.1293,  0.0405,  0.1639, -0.0579,  0.0094, -0.0380,\n",
       "          -0.0760,  0.0700,  0.0739,  0.1698,  0.0711,  0.0453, -0.0453, -0.1051],\n",
       "         [ 0.1041,  0.0687,  0.1589,  0.0505,  0.0924, -0.1001,  0.1026, -0.0535,\n",
       "           0.1312, -0.1525, -0.1623,  0.0663,  0.1647,  0.0823,  0.0076, -0.1117,\n",
       "           0.0436, -0.0673, -0.1504,  0.1158, -0.0378,  0.0413, -0.0122, -0.0412,\n",
       "           0.1252,  0.0371,  0.1428, -0.0038,  0.1043, -0.0183,  0.0366,  0.1277]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0434, -0.0221,  0.1524, -0.0516,  0.0357,  0.0107,  0.1203,  0.0846,\n",
       "         -0.0551,  0.1750], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss :  2.321671724319458\n"
     ]
    }
   ],
   "source": [
    "for image,label in train_dl:\n",
    "    pred = model(image)\n",
    "    loss = F.cross_entropy(pred , label)\n",
    "    print('Initial loss : ' , loss.item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Data To GPU In Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda:0')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DigitClassification().to(device) # passes model to GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters() , lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 , Loss : 2.2961463928222656\n",
      "Iteration 1 , Loss : 2.2979562282562256\n",
      "Iteration 2 , Loss : 2.2807695865631104\n",
      "Iteration 3 , Loss : 1.5430907011032104\n",
      "Iteration 4 , Loss : 0.4101593494415283\n",
      "Iteration 5 , Loss : 0.17360679805278778\n",
      "Iteration 6 , Loss : 0.2147565633058548\n",
      "Iteration 7 , Loss : 0.19921329617500305\n",
      "Iteration 8 , Loss : 0.315003365278244\n",
      "Iteration 9 , Loss : 0.19939474761486053\n",
      "Iteration 10 , Loss : 0.08917412906885147\n",
      "Iteration 11 , Loss : 0.12175825238227844\n",
      "Iteration 12 , Loss : 0.056401580572128296\n",
      "Iteration 13 , Loss : 0.0675685703754425\n",
      "Iteration 14 , Loss : 0.10517005622386932\n",
      "Iteration 15 , Loss : 0.13912509381771088\n",
      "Iteration 16 , Loss : 0.030759291723370552\n",
      "Iteration 17 , Loss : 0.07281431555747986\n",
      "Iteration 18 , Loss : 0.1338278353214264\n",
      "Iteration 19 , Loss : 0.030923137441277504\n",
      "Iteration 20 , Loss : 0.03832457587122917\n",
      "Iteration 21 , Loss : 0.06417449563741684\n",
      "Iteration 22 , Loss : 0.031947068870067596\n",
      "Iteration 23 , Loss : 0.050020355731248856\n"
     ]
    }
   ],
   "source": [
    "iteration = []\n",
    "loss_set = []\n",
    "\n",
    "for i in range(24):\n",
    "    for image,label in train_dl:\n",
    "        pred = model(image)\n",
    "        loss = F.cross_entropy(pred , label)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "    iteration.append(i)\n",
    "    loss_set.append(float(\"{:.2f}\".format(loss)))\n",
    "\n",
    "    print(f'Iteration {i} , Loss : {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot For Loss Decrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iteration')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration , loss_set)\n",
    "plt.title('Iteration Vs Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = MNIST(root = '.' , train = False , transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: .\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "test_dl = DataLoader(testset , batch_size , sampler = SubsetRandomSampler(np.random.permutation(len(testset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DeviceDataLoader(test_dl, device) # passes data to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryanshridhar/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for image,label in test_dl:\n",
    "    pred = model(image)\n",
    "    for i in range(len(pred)):\n",
    "        _ , index = torch.max(F.softmax(pred[i]), dim = 0)\n",
    "        if index.item() == label[i].item():\n",
    "            correct += 1\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 98%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy is {round((correct/total)*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
