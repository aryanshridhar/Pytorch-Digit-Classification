{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root = '.' , download = True , transform = ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: .\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a44373810>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[0][0][0,:,:] , cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a442d83d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[1][0][0,:,:] , cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 73, 43, 92, 83, 48, 45, 39, 77, 66, 14, 59, 72, 82, 36, 68,  9,\n",
       "       44, 26, 94, 85, 23, 51, 37, 96, 52, 30, 91, 17, 49, 57, 31, 50, 19,\n",
       "       61, 90, 53, 12, 60, 41, 76,  5, 80, 56, 75, 70, 55,  7, 95, 24,  6,\n",
       "       10, 27, 38, 46, 11, 93, 78,  0,  3, 79, 62, 32, 35, 71, 22,  2, 33,\n",
       "       47, 98,  4, 40, 69, 86,  8, 67, 81, 58, 15, 29, 74, 34, 21, 18, 63,\n",
       "       99, 87, 97,  1, 42, 25, 65, 54, 28, 20, 84, 64, 13, 89, 88])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n, val_pct):\n",
    "    # Determine size of validation set\n",
    "    n_val = int(val_pct*n)\n",
    "    # Create random permutation of 0 to n-1\n",
    "    idxs = np.random.permutation(n)\n",
    "    # Pick first n_val indices for validation set\n",
    "    return idxs[n_val:], idxs[:n_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = split_indices(len(dataset), val_pct=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "\n",
    "# Training sampler and data loader\n",
    "train_sampler = SubsetRandomSampler(train_indices) # random shulffes and creates a sample\n",
    "train_dl = DataLoader(dataset, \n",
    "                      batch_size, \n",
    "                      sampler=train_sampler) # a sampler is passed to let pytorch know that it has to only use the subset determined by these indexes\n",
    "\n",
    "# Validation sampler and data loader\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "valid_dl = DataLoader(dataset,\n",
    "                    batch_size, \n",
    "                    sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dl:\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0., 11.,  0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([-1,11,-3.12])\n",
    "torch.relu(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitModel(nn.Module):\n",
    "    def __init__(self , input_size , hidden_size , output_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size , hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size , output_size)\n",
    "    \n",
    "    \n",
    "    def forward(self , batch):\n",
    "        batch = batch.view(batch.size(0), -1)\n",
    "        out = self.linear1(batch)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28*28\n",
    "hidden_size = 32\n",
    "output_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DigitModel(input_size , hidden_size , output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0137,  0.0213,  0.0002,  ...,  0.0256, -0.0081, -0.0006],\n",
       "         [ 0.0114, -0.0114, -0.0238,  ...,  0.0144,  0.0277,  0.0022],\n",
       "         [-0.0004, -0.0240, -0.0011,  ..., -0.0030, -0.0177, -0.0055],\n",
       "         ...,\n",
       "         [ 0.0165,  0.0049, -0.0033,  ...,  0.0332, -0.0316, -0.0131],\n",
       "         [-0.0346, -0.0084,  0.0016,  ..., -0.0239,  0.0331, -0.0010],\n",
       "         [-0.0172, -0.0243,  0.0224,  ..., -0.0289,  0.0142, -0.0276]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0091, -0.0066,  0.0297,  0.0216, -0.0250, -0.0320, -0.0183, -0.0038,\n",
       "         -0.0200,  0.0255,  0.0277, -0.0236, -0.0243,  0.0103, -0.0152, -0.0181,\n",
       "         -0.0138, -0.0205, -0.0054, -0.0342, -0.0071, -0.0306, -0.0036,  0.0285,\n",
       "          0.0272,  0.0125,  0.0349,  0.0178, -0.0091,  0.0073,  0.0105,  0.0256],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0733, -0.0361,  0.1712, -0.1618, -0.0228, -0.1129,  0.0875, -0.1595,\n",
       "           0.0298,  0.0317, -0.0185, -0.1552,  0.1509, -0.0327, -0.1759,  0.1486,\n",
       "          -0.1528,  0.0298, -0.0714, -0.0199, -0.1301, -0.1095,  0.1139, -0.1382,\n",
       "          -0.0089,  0.0462, -0.1546,  0.0600, -0.0682, -0.1165,  0.0471,  0.0508],\n",
       "         [ 0.0842,  0.0933, -0.1237,  0.0770, -0.0177, -0.0205, -0.0963,  0.1565,\n",
       "          -0.1571,  0.1614, -0.0227, -0.0283,  0.0028,  0.0925, -0.0118, -0.1192,\n",
       "           0.0862, -0.1486, -0.0594, -0.1440, -0.0777, -0.1700,  0.1628,  0.1754,\n",
       "          -0.0201, -0.1698,  0.1100, -0.1683,  0.0605,  0.0837, -0.1181,  0.1354],\n",
       "         [-0.0215, -0.1102, -0.0910, -0.1053,  0.1458,  0.1525,  0.1509, -0.1286,\n",
       "           0.0056,  0.0029,  0.1676, -0.1374, -0.1642,  0.0155,  0.1337,  0.0223,\n",
       "           0.0753,  0.1148, -0.1112, -0.1509, -0.0844,  0.1342,  0.0018,  0.1225,\n",
       "          -0.1369, -0.0984, -0.1061,  0.0412,  0.0734, -0.0253, -0.1623,  0.1250],\n",
       "         [ 0.0157, -0.1746, -0.0205,  0.1543, -0.1506,  0.0801, -0.0273, -0.0638,\n",
       "           0.0509, -0.1342, -0.0447, -0.0222,  0.1656,  0.0586,  0.0673,  0.1628,\n",
       "           0.1557, -0.1547,  0.0866,  0.0323,  0.1512,  0.0942, -0.0979,  0.0570,\n",
       "          -0.1417,  0.0857, -0.1767, -0.1385,  0.1070, -0.1625,  0.0251,  0.0704],\n",
       "         [ 0.0356,  0.1236, -0.0452, -0.1344,  0.1438, -0.0431,  0.0429, -0.0733,\n",
       "           0.0139,  0.1474, -0.1691,  0.0971, -0.1640, -0.0643, -0.1065, -0.0810,\n",
       "           0.0687,  0.0464, -0.1653, -0.1674,  0.1202,  0.0595,  0.0992, -0.0523,\n",
       "          -0.1707, -0.0809,  0.0632,  0.0147,  0.0257,  0.1319,  0.1172,  0.0833],\n",
       "         [ 0.0656,  0.0356, -0.1372,  0.0136,  0.0852, -0.0349, -0.1655, -0.1266,\n",
       "          -0.1015,  0.0972, -0.1754,  0.0954, -0.0905,  0.0386, -0.0868,  0.1073,\n",
       "          -0.1711, -0.0225, -0.0345, -0.0297,  0.0813, -0.0179, -0.0641, -0.1138,\n",
       "           0.1094, -0.0713, -0.0837, -0.0214,  0.0187, -0.0922,  0.1143, -0.0611],\n",
       "         [-0.0910,  0.0107,  0.1624,  0.0320, -0.0184,  0.0273,  0.1210,  0.0963,\n",
       "          -0.0834,  0.1102,  0.1034, -0.1652,  0.0305,  0.1597,  0.0515,  0.0260,\n",
       "          -0.0845,  0.0175,  0.0061,  0.1081,  0.0381, -0.0538, -0.1618,  0.0223,\n",
       "           0.0334,  0.0348, -0.1017,  0.1445,  0.1143,  0.1368,  0.1095,  0.0603],\n",
       "         [-0.0019,  0.1090, -0.1660,  0.0599,  0.1058, -0.0331,  0.0690, -0.0490,\n",
       "          -0.0096, -0.1550, -0.1594, -0.1551,  0.1463,  0.0596,  0.0179, -0.1310,\n",
       "          -0.0764,  0.1410, -0.0791, -0.1145,  0.1218,  0.0288, -0.1543, -0.1270,\n",
       "           0.0544, -0.0211, -0.0707,  0.0858, -0.1078, -0.0539, -0.0456, -0.0912],\n",
       "         [-0.0007, -0.1193, -0.0946,  0.0285, -0.0967,  0.1431,  0.0619,  0.0828,\n",
       "          -0.0812,  0.1074, -0.0583, -0.1091, -0.1375,  0.0042,  0.0055, -0.0584,\n",
       "           0.0027,  0.1229,  0.1542,  0.0708, -0.1566, -0.0325,  0.0490, -0.1720,\n",
       "          -0.0490,  0.0469, -0.0377, -0.1116, -0.0644, -0.0344,  0.0869, -0.1362],\n",
       "         [-0.1734, -0.0968, -0.0603, -0.1594,  0.1506,  0.0693,  0.1227,  0.0737,\n",
       "           0.1244,  0.1293, -0.0021, -0.1668,  0.0739,  0.0538,  0.1572, -0.1163,\n",
       "          -0.0794,  0.1004, -0.0477, -0.1079,  0.0832,  0.0146,  0.0192, -0.1064,\n",
       "          -0.0170,  0.1568,  0.0514, -0.0282, -0.0979,  0.0371,  0.1497,  0.0965]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1337,  0.1401,  0.0390,  0.1422,  0.0105, -0.1140,  0.1396, -0.0790,\n",
       "         -0.1164, -0.0074], requires_grad=True)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters()) # conains all randomly initialized weights and biases required by the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 32])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inital Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially Loss: 2.3203444480895996\n",
      "5\n",
      "torch.Size([100, 10])\n",
      "tensor([-0.1519,  0.0736,  0.0231,  0.1953,  0.0243, -0.0875,  0.2097, -0.1052,\n",
      "        -0.1140,  0.0442], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dl:\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    print('Initially Loss:', loss.item())\n",
    "    break\n",
    "\n",
    "print(labels[-1].item())\n",
    "print(outputs.shape)\n",
    "print(outputs[-1 , :]) # gives vector with length 10 , representing the probability of each of the digit .\n",
    "                       # Since probabilty needs to be between [0-1] with the sum as 1 , Apply Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0843, 0.1057, 0.1005, 0.1193, 0.1006, 0.0899, 0.1211, 0.0884, 0.0876,\n",
      "        0.1026], grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryanshridhar/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(F.softmax(outputs[-1 , :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters() , lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training On CPU :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1119283437728882\n",
      "0.4852154850959778\n",
      "0.37561050057411194\n",
      "0.31124138832092285\n",
      "0.2469370812177658\n",
      "0.21608783304691315\n",
      "0.3427141308784485\n",
      "0.3668327033519745\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,16):\n",
    "    for batch,label in train_dl:\n",
    "        pred = model(batch)\n",
    "        loss = F.cross_entropy(pred , label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    if i%2 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrected Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0137,  0.0213,  0.0002,  ...,  0.0256, -0.0081, -0.0006],\n",
      "        [ 0.0114, -0.0114, -0.0238,  ...,  0.0144,  0.0277,  0.0022],\n",
      "        [-0.0004, -0.0240, -0.0011,  ..., -0.0030, -0.0177, -0.0055],\n",
      "        ...,\n",
      "        [ 0.0165,  0.0049, -0.0033,  ...,  0.0332, -0.0316, -0.0131],\n",
      "        [-0.0346, -0.0084,  0.0016,  ..., -0.0239,  0.0331, -0.0010],\n",
      "        [-0.0172, -0.0243,  0.0224,  ..., -0.0289,  0.0142, -0.0276]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1072,  0.0671,  0.0233,  0.0968,  0.1741, -0.1693, -0.1421, -0.0039,\n",
      "        -0.0322,  0.0500, -0.0280,  0.0974,  0.0834,  0.0105, -0.0665,  0.0486,\n",
      "        -0.0815, -0.0429, -0.0146, -0.0866,  0.2551, -0.0078, -0.0449,  0.1691,\n",
      "         0.0971, -0.0586,  0.0933,  0.2051,  0.0739,  0.0701,  0.0844,  0.0490],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-2.2961e-01, -1.6065e-02,  1.7128e-01, -4.5661e-01, -8.3218e-02,\n",
      "         -3.0975e-01,  2.6987e-01, -4.3956e-01,  5.5715e-02, -6.4159e-02,\n",
      "          1.6042e-02, -3.2347e-01,  4.3889e-01, -3.3688e-02, -3.3163e-01,\n",
      "          9.3631e-01, -2.1254e-01,  1.2208e-01, -7.2991e-02, -7.6055e-03,\n",
      "         -4.3116e-01, -1.5247e-01,  4.1507e-01, -5.5061e-01, -2.5356e-02,\n",
      "          2.2275e-01, -3.6898e-01,  3.8895e-01, -2.7743e-01, -3.5491e-01,\n",
      "          1.5742e-02,  2.1914e-02],\n",
      "        [ 3.1818e-01,  2.3766e-01, -1.2363e-01,  3.9739e-01, -2.6177e-01,\n",
      "         -1.1298e-01, -4.3545e-01,  5.8382e-01, -2.3896e-01,  1.9043e-01,\n",
      "         -9.1774e-02,  1.8967e-02,  6.9990e-02,  9.5527e-02, -1.8818e-02,\n",
      "         -5.1434e-01,  8.2927e-02, -4.5757e-01, -6.0998e-02, -2.3955e-01,\n",
      "         -3.4529e-01, -2.0563e-01,  2.0864e-01,  6.9525e-01, -1.0259e-02,\n",
      "         -3.8986e-01,  4.1500e-01, -5.3367e-01,  9.8149e-02,  3.3143e-02,\n",
      "         -4.3931e-01,  1.0606e-01],\n",
      "        [ 1.2262e-02, -2.0602e-01, -9.0004e-02, -2.1549e-01,  3.9882e-01,\n",
      "          4.7981e-01,  3.3222e-01, -3.1470e-01,  1.6995e-02, -8.7687e-02,\n",
      "          5.3646e-01, -2.3567e-01, -4.2138e-01,  1.7442e-02,  4.1608e-01,\n",
      "          3.1941e-01,  1.6358e-01,  3.4093e-01, -1.1177e-01, -2.5958e-01,\n",
      "         -3.7610e-01,  1.5604e-01,  1.0788e-01,  6.4428e-01, -1.6574e-01,\n",
      "         -3.2002e-01, -2.8831e-01, -2.6556e-02,  2.4866e-01, -2.4212e-01,\n",
      "         -5.3385e-01,  2.3063e-01],\n",
      "        [ 1.0157e-01, -2.4675e-01, -2.0515e-02,  4.3615e-01, -3.0117e-01,\n",
      "          4.0301e-01, -1.4517e-01, -3.3874e-01,  2.7465e-01, -4.8273e-01,\n",
      "         -1.0904e-01,  2.2506e-02,  4.6385e-01,  5.9484e-02,  2.4171e-01,\n",
      "          2.8808e-01,  4.1571e-01, -3.9953e-01,  8.4736e-02,  5.2423e-02,\n",
      "          4.3504e-01,  1.9234e-01, -1.5540e-01,  2.9708e-01, -1.8373e-01,\n",
      "          1.3835e-01, -4.3974e-01, -5.1789e-01,  2.5416e-01, -3.8257e-01,\n",
      "         -6.0668e-02,  3.0464e-01],\n",
      "        [-1.1399e-01,  1.7247e-01, -4.5595e-02, -4.4654e-01,  3.4272e-01,\n",
      "         -1.5826e-01,  1.5690e-01, -3.2893e-01,  3.5064e-02,  3.9872e-01,\n",
      "         -4.3169e-01,  4.8424e-01, -5.9509e-01, -6.4791e-02, -4.4733e-01,\n",
      "         -5.2569e-01,  3.6014e-01, -5.8173e-02, -1.6653e-01, -2.8433e-01,\n",
      "          4.1920e-01,  1.5228e-01,  7.5042e-02, -3.5409e-01, -2.7841e-01,\n",
      "         -2.1193e-01,  2.0733e-01,  1.4730e-01,  7.2420e-02,  7.3279e-01,\n",
      "          4.0027e-01,  3.4962e-01],\n",
      "        [ 3.6662e-01,  2.2899e-01, -1.3645e-01,  8.9556e-02,  8.5725e-02,\n",
      "         -2.0925e-01, -6.3667e-01, -1.3833e-01, -2.2145e-01,  3.6078e-01,\n",
      "         -2.6237e-01,  2.6126e-01, -2.0966e-01,  3.9140e-02, -2.7240e-01,\n",
      "          7.5282e-01, -4.5020e-01, -6.1886e-04, -3.2038e-02,  2.4803e-01,\n",
      "          1.6474e-01, -5.9084e-02, -1.9801e-01, -1.7669e-01,  2.8595e-01,\n",
      "         -1.0118e-01, -1.7360e-01,  2.7202e-02,  8.1783e-02, -2.1257e-01,\n",
      "          6.2713e-01, -3.6199e-01],\n",
      "        [-5.2108e-01, -1.0978e-03,  1.6199e-01, -2.1872e-01, -3.5303e-01,\n",
      "         -3.8668e-01,  2.7364e-01,  2.4553e-01, -2.8512e-01,  2.5418e-01,\n",
      "          4.4100e-01, -2.2912e-01, -2.3986e-01,  1.5781e-01, -1.4734e-01,\n",
      "         -8.8659e-02, -2.1684e-01, -1.9281e-01,  4.1766e-03,  2.1870e-01,\n",
      "         -4.1331e-01, -8.3445e-02, -4.3146e-01,  1.0384e-01, -8.8587e-03,\n",
      "         -4.2852e-02, -4.2899e-01,  5.6076e-01,  5.4083e-01,  7.4035e-01,\n",
      "          4.1067e-02,  7.4206e-02],\n",
      "        [ 6.2330e-02,  1.8023e-01, -1.6594e-01,  3.1852e-01,  5.4631e-01,\n",
      "         -1.7313e-01,  1.4423e-01, -1.8265e-01, -2.1566e-02, -6.0010e-01,\n",
      "         -3.8504e-01, -3.4725e-01,  5.6309e-01,  6.1640e-02,  5.5079e-02,\n",
      "         -6.1882e-01, -1.3720e-01,  4.3984e-01, -7.2829e-02, -3.7519e-01,\n",
      "          7.0883e-01,  5.3200e-02, -2.6473e-01,  7.5441e-02,  1.7702e-01,\n",
      "         -2.2801e-02,  1.4304e-01,  3.8022e-01, -2.1323e-01, -3.9286e-01,\n",
      "         -3.5284e-01, -2.5546e-01],\n",
      "        [ 2.6921e-01, -3.5093e-01, -9.5092e-02,  2.9738e-01, -3.8097e-01,\n",
      "          4.7945e-01,  2.8107e-01,  3.0047e-01, -1.1668e-01,  3.7915e-01,\n",
      "          1.8369e-02, -7.5108e-02, -3.4272e-01,  1.1119e-03,  3.4973e-02,\n",
      "          1.5818e-02,  3.6328e-02,  4.3376e-01,  1.5239e-01,  3.0868e-01,\n",
      "         -4.0516e-01, -5.6388e-02,  2.2512e-01, -4.4478e-01, -1.1238e-01,\n",
      "          1.6145e-01,  2.0724e-01, -3.1607e-01, -2.0801e-01, -5.8091e-02,\n",
      "          2.6570e-01, -2.3953e-01],\n",
      "        [-4.2620e-01, -1.6334e-01, -6.0769e-02, -3.9717e-01,  3.3157e-01,\n",
      "          2.1562e-01,  1.2625e-01,  4.2153e-01,  2.9319e-01,  1.4982e-01,\n",
      "         -1.1103e-01, -3.2315e-01,  2.8659e-01,  5.1805e-02,  5.2183e-01,\n",
      "         -6.0383e-01, -2.1766e-01,  1.9057e-02, -4.5685e-02, -1.8455e-01,\n",
      "          3.9031e-01, -4.9039e-02, -1.4567e-02, -6.2226e-01, -2.5219e-02,\n",
      "          4.9516e-01,  2.2037e-01, -2.3198e-01, -5.3594e-01,  4.1436e-02,\n",
      "          3.6052e-01,  1.0312e-01]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1858,  0.2622, -0.0054,  0.0476,  0.0007,  0.2292, -0.0250,  0.1176,\n",
      "        -0.3622, -0.0582], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy On Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
